# ğŸµ PENGENALAN EMOSI MUSIK MULTIMODAL BERBASIS LATE FUSION PADA DATASET MULTI-MODAL MIREX  
**Tugas Besar Pembelajaran Mesin Multimodal (IF25-40304)**  
Kelompok 09 â€” Institut Teknologi Sumatera  

---

## ğŸ“Œ Ringkasan Proyek  
Proyek ini mengembangkan sistem **Multimodal Music Emotion Recognition (MER)** untuk mengklasifikasikan lagu ke dalam **5 klaster emosi MIREX** dengan memanfaatkan tiga modalitas utama: **Audio, Lyrics, dan MIDI**.  

Pendekatan **Late Fusion** digunakan untuk menggabungkan informasi emosional dari setiap modalitas, yang diproses terlebih dahulu menggunakan encoder khusus:  
- **CRNN** untuk audio,  
- **BERT** untuk lirik,  
- **BiGRU** untuk MIDI.  

Setiap modalitas memiliki karakteristik emosional unik sehingga penggabungan output-nya diharapkan meningkatkan akurasi model dibandingkan pendekatan unimodal.

---

## ğŸ“‚ Dataset  
Dataset multimodal mengacu pada kerangka kerja *MIREX Mood Classification* serta metodologi yang diperkenalkan oleh Panda et al. (2013).  

### Ketersediaan Data  
| Modalitas | Jumlah Sampel | Keterangan |
|----------|----------------|------------|
| Audio    | 903 sampel     | 100% tersedia |
| Lyrics   | 764 sampel     | ~85% dari audio |
| MIDI     | 193 sampel     | ~21% dari audio |

### Label Emosi (MIREX Clusters)
1. Passionate / Rousing / Confident / Boisterous / Rowdy  
2. Cheerful / Fun / Sweet / Amiable  
3. Poignant / Wistful / Brooding  
4. Humorous / Quirky / Witty  
5. Aggressive / Tense / Intense  

---

## ğŸ§ª Arsitektur Model  
Arsitektur baseline terdiri dari tiga cabang pemrosesan paralel yang masing-masing menghasilkan logit atau probabilitas sebelum digabungkan melalui Late Fusion.

```
Audio  â†’ CRNN  â†’ Classifier_A â†’ P_A
Lyrics â†’ BERT  â†’ Classifier_L â†’ P_L
MIDI   â†’ BiGRU â†’ Classifier_M â†’ P_M
                â†“
        Late Fusion (+ / concat)
                â†“
             FC Layer
                â†“
          Final Output
```

Keuntungan Late Fusion:  
- Tidak sensitif terhadap missing modality  
- Memungkinkan setiap encoder belajar optimal  
- Memberikan interpretabilitas kontribusi modalitas  

---

## ğŸ” Exploratory Data Analysis (EDA) â€” Ringkasan  
Beberapa temuan utama:

### âœ“ Intra-modal  
- **Audio**: Mel-Spectrogram menampilkan pola energi berbeda antar klaster.  
- **Lyrics**: Didominasi kata emosional seperti *love*, *pain*, *heart*. Variasi panjang teks besar â†’ perlu padding/truncation.  
- **MIDI**: Distribusi pitch & velocity bervariasi; modalitas paling sedikit dan paling noisy.

### âœ“ Inter-modal  
Setiap modalitas memuat informasi emosional berbeda â†’ mendukung pentingnya pendekatan multimodal.

### âœ“ Kualitas Label  
Distribusi klaster tidak seimbang sehingga perlu strategi training yang tepat.

### âœ“ t-SNE  
Embedding tiap modalitas belum membentuk cluster emosional jelas â†’ model nonlinear + fusion sangat diperlukan.

---

## âš™ï¸ Setup Eksperimen  
### Preprocessing  
- **Audio**:  
  - Resampling 22.050 Hz  
  - Mono, durasi seragam 30 detik  
  - Log-Mel Spectrogram (128 mel bands)  
- **Lyrics**:  
  - Tokenisasi BERT  
  - Max length 128/256  
  - Padding & truncation  
- **MIDI**:  
  - Ekstraksi event â†’ embedding â†’ BiGRU  

### Hyperparameter  
- Optimizer: Adam / AdamW  
- LR: 1e-3 (audio), 2e-5 (lyrics), 1e-3 (MIDI)  
- Batch Size: 8â€“16  
- Epoch: 10â€“20  

### Data Splitting  
- Unimodal: 80% train â€” 20% validation (stratified)  
- Multimodal baseline: seluruh intersection (193 sampel)

---

## ğŸ“ˆ Hasil Baseline (Unimodal)

### **Lyrics (BERT)**  
- Akurasi validasi ~40â€“45%  
- Kesalahan banyak pada kelas dengan kemiripan semantik  

### **Audio (CRNN)**  
- Akurasi maksimum sekitar 43%  
- Training cenderung underfitting  

### **MIDI (BiGRU)**  
- Performa rendah karena dataset sangat kecil  

**Kesimpulan:**  
Tidak ada modalitas yang cukup kuat secara individual â†’ Multimodal Late Fusion sangat direkomendasikan.

---

## ğŸš€ Rencana Pengembangan  
- Membangun dan melatih **model multimodal Late Fusion end-to-end**  
- Uji beberapa strategi fusi: concatenation, weighted sum, attention-based fusion  
- Tambah fitur audio: MFCC, chroma, spectral contrast  
- Augmentasi audio (pitch/time shift)  
- Augmentasi MIDI (transposition)  
- Tuning hyperparameter lanjutan untuk stabilitas training  

---

## ğŸ“ Struktur Repository  
```
.
â”œâ”€â”€ data/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio_model/
â”‚   â”œâ”€â”€ lyrics_model/
â”‚   â”œâ”€â”€ midi_model/
â”‚   â”œâ”€â”€ fusion/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb
â”‚   â”œâ”€â”€ Baseline_Audio.ipynb
â”‚   â”œâ”€â”€ Baseline_Lyrics.ipynb
â”‚   â”œâ”€â”€ Baseline_MIDI.ipynb
â”‚   â””â”€â”€ Fusion_Model.ipynb
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ Proposal.pdf
â”‚   â”œâ”€â”€ EDA.pdf
â”‚   â”œâ”€â”€ Preliminary_Experiment.pdf
â”‚   â””â”€â”€ Final_Report.pdf
â””â”€â”€ README.md
```

---

## ğŸ‘¥ Anggota Kelompok  
- Lois Novel E. Gurning â€” 122140098  
- Sakti Mujahid Imani â€” 122140123  
- Apridian Saputra â€” 122140143  
- Joshia Fernandes Sectio Purba â€” 122140170  
- Sikah Nubuahtul Ilmi â€” 122140208  

---

## ğŸ“ Lisensi  
Project ini dibuat untuk keperluan akademik dalam mata kuliah  
**Pembelajaran Mesin Multimodal (IF25-40304)**, Institut Teknologi Sumatera.

